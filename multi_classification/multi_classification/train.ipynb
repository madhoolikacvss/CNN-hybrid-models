{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/drive')\n","# !ln -s \"/drive/MyDrive/LeafDisease\" \"/content/LeafDisease\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jy7aVPpYuXwD","executionInfo":{"status":"ok","timestamp":1755623106925,"user_tz":420,"elapsed":7250,"user":{"displayName":"Madhoolika Chodavarapu","userId":"11907149759282583571"}},"outputId":"6d64b508-95e3-4131-b064-4c668b13bd47"},"id":"Jy7aVPpYuXwD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}]},{"cell_type":"code","source":["!ln -s \"/drive/MyDrive/LeafDisease\" \"/content/LeafDisease\""],"metadata":{"id":"NB06DFOLVUOa"},"id":"NB06DFOLVUOa","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ed557981-8b06-492d-aad0-2ceb55f2923f","metadata":{"id":"ed557981-8b06-492d-aad0-2ceb55f2923f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755623808998,"user_tz":420,"elapsed":134,"user":{"displayName":"Madhoolika Chodavarapu","userId":"11907149759282583571"}},"outputId":"39e927a5-1d54-4345-cad8-5e7d5fb24740"},"outputs":[{"output_type":"stream","name":"stdout","text":["LeafDisease  sample_data\n"]}],"source":["# %run \"/content/LeafDisease/dataset/datasetup.ipynb\"\n","!ls"]},{"cell_type":"code","execution_count":3,"id":"480431e2-8251-4f04-8b72-81b4de588c71","metadata":{"id":"480431e2-8251-4f04-8b72-81b4de588c71","executionInfo":{"status":"ok","timestamp":1755636781658,"user_tz":420,"elapsed":6537,"user":{"displayName":"Madhoolika Chodavarapu","userId":"11907149759282583571"}}},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, classification_report, accuracy_score\n","import pickle\n","import numpy as np\n","from google.colab import files\n","import pandas as pd\n","import seaborn as sns\n"]},{"cell_type":"code","execution_count":4,"id":"8d33d34c-e843-4f33-99b7-a23752525905","metadata":{"id":"8d33d34c-e843-4f33-99b7-a23752525905","executionInfo":{"status":"ok","timestamp":1755636781680,"user_tz":420,"elapsed":7,"user":{"displayName":"Madhoolika Chodavarapu","userId":"11907149759282583571"}}},"outputs":[],"source":["class MultiClassClassifierTrainer:\n","    def __init__(self, device, class_names):\n","        self.device = device\n","        self.class_names = class_names\n","        self.num_classes = len(class_names)\n","\n","    def plot_history(self, history, model_name=\"model\"):\n","        \"\"\"Plot training/validation metrics\"\"\"\n","        plt.figure(figsize=(18, 6))\n","\n","        # Loss plot\n","        plt.subplot(1, 3, 1)\n","        plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n","        plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"Loss\")\n","        plt.title(\"Loss Curve\")\n","        plt.legend()\n","\n","        # Accuracy plot\n","        plt.subplot(1, 3, 2)\n","        plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n","        plt.plot(history[\"val_acc\"], label=\"Val Acc\")\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.title(\"Accuracy Curve\")\n","        plt.legend()\n","\n","        # F1 Score plot (macro average for multi-class)\n","        plt.subplot(1, 3, 3)\n","        plt.plot(history[\"val_f1_macro\"], label=\"Val F1 (Macro)\", color='purple')\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"F1 Score\")\n","        plt.title(\"F1 Score Curve (Macro Average)\")\n","        plt.legend()\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def eval_plot(self, y_true, y_pred, model_name=\"model\"):\n","        \"\"\"Plot confusion matrix for multi-class\"\"\"\n","        conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","        print(\"Confusion Matrix:\\n\", conf_matrix)\n","        print(f\"Overall Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n","        print(f\"Macro F1: {f1_score(y_true, y_pred, average='macro'):.4f}\")\n","\n","        disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n","                                    display_labels=self.class_names)\n","        fig, ax = plt.subplots(figsize=(12, 10))\n","        disp.plot(ax=ax, cmap='Blues', values_format='d', xticks_rotation=45)\n","        plt.title(f\"Confusion Matrix - {model_name}\")\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def plot_roc(self, model, dataloader, model_name=\"model\"):\n","        \"\"\"Plot ROC curves for multi-class (one-vs-rest)\"\"\"\n","        model.eval()\n","        y_true, y_probs = [], []\n","\n","        with torch.no_grad():\n","            for inputs, labels in dataloader:\n","                inputs = inputs.to(self.device)\n","                labels = labels.to(self.device)\n","                outputs = model(inputs)\n","                probs = torch.softmax(outputs, dim=1)\n","                y_true.extend(labels.cpu().numpy())\n","                y_probs.extend(probs.detach().cpu().numpy())\n","\n","        y_true = np.array(y_true)\n","        y_probs = np.array(y_probs)\n","\n","        # Plot ROC for each class\n","        plt.figure(figsize=(10, 8))\n","        for i in range(self.num_classes):\n","            fpr, tpr, _ = roc_curve(y_true == i, y_probs[:, i])\n","            roc_auc = auc(fpr, tpr)\n","            plt.plot(fpr, tpr, lw=2,\n","                    label=f'{self.class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","        plt.xlabel('False Positive Rate')\n","        plt.ylabel('True Positive Rate')\n","        plt.title(f'Multi-class ROC Curves - {model_name}')\n","        plt.legend(loc='lower right')\n","        plt.grid(True)\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def train(self, model, criterion, optimizer, dataloaders, image_datasets,\n","              num_epochs=10, patience=3, save_path=\"history.pkl\"):\n","        \"\"\"Train model with early stopping for multi-class\"\"\"\n","        history = {\n","            \"train_loss\": [], \"train_acc\": [],\n","            \"val_loss\": [], \"val_acc\": [],\n","            \"val_f1_macro\": [], \"val_f1_weighted\": []\n","        }\n","        best_loss = float('inf')\n","        epochs_no_improve = 0\n","\n","        for epoch in range(num_epochs):\n","            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n","\n","            for phase in [\"train\", \"val\"]:\n","                model.train() if phase == \"train\" else model.eval()\n","\n","                running_loss = 0.0\n","                running_corrects = 0\n","                all_true, all_preds = [], []\n","\n","                for inputs, labels in dataloaders[phase]:\n","                    inputs = inputs.to(self.device)\n","                    labels = labels.to(self.device)\n","\n","                    optimizer.zero_grad()\n","\n","                    with torch.set_grad_enabled(phase == \"train\"):\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","                        _, preds = torch.max(outputs, 1)\n","\n","                        if phase == \"train\":\n","                            loss.backward()\n","                            optimizer.step()\n","\n","                    all_true.extend(labels.cpu().numpy())\n","                    all_preds.extend(preds.cpu().numpy())\n","                    running_loss += loss.item() * inputs.size(0)\n","                    running_corrects += torch.sum(preds == labels.data)\n","\n","                epoch_loss = running_loss / len(image_datasets[phase])\n","                epoch_acc = running_corrects.float() / len(image_datasets[phase])\n","\n","                history[f\"{phase}_loss\"].append(epoch_loss)\n","                history[f\"{phase}_acc\"].append(epoch_acc.item())\n","\n","                if phase == \"val\":\n","                    # Multi-class F1 scores\n","                    f1_macro = f1_score(all_true, all_preds, average='macro')\n","                    f1_weighted = f1_score(all_true, all_preds, average='weighted')\n","                    history[\"val_f1_macro\"].append(f1_macro)\n","                    history[\"val_f1_weighted\"].append(f1_weighted)\n","\n","                    # Early stopping\n","                    if epoch_loss < best_loss:\n","                        best_loss = epoch_loss\n","                        epochs_no_improve = 0\n","                        torch.save(model.state_dict(), \"best_model.pth\")\n","                        best_true, best_preds = all_true, all_preds\n","                    else:\n","                        epochs_no_improve += 1\n","\n","                    if epochs_no_improve >= patience:\n","                        print(\"Early stopping triggered\")\n","                        return model, history, best_true, best_preds\n","\n","                print(f\"{phase} Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\",\n","                      end=f\" | F1 Macro: {f1_macro:.4f}\" if phase == \"val\" else \"\")\n","                print(f\" | F1 Weighted: {f1_weighted:.4f}\" if phase == \"val\" else \"\")\n","\n","        return model, history, best_true, best_preds\n","\n","    def plot_classification_report(self, y_true, y_pred, model_name=\"model\"):\n","        \"\"\"Plot detailed classification report\"\"\"\n","        report = classification_report(y_true, y_pred,\n","                                     target_names=self.class_names,\n","                                     output_dict=True)\n","\n","        # Convert to DataFrame for better visualization\n","        report_df = pd.DataFrame(report).transpose()\n","\n","        plt.figure(figsize=(12, 8))\n","        sns.heatmap(report_df.iloc[:-3, :-1].astype(float),\n","                   annot=True, cmap='Blues', fmt='.3f')\n","        plt.title(f\"Classification Report - {model_name}\")\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return report_df\n","    def compare_models(self, models_info, dataloader):\n","      \"\"\"Compare multiple models using macro F1 scores\"\"\"\n","      plt.figure(figsize=(10, 6))\n","\n","      for name, model in models_info:\n","          model = model.to(self.device)\n","          model.eval()\n","          all_true, all_preds = [], []\n","\n","          with torch.no_grad():\n","              for inputs, labels in dataloader:\n","                  inputs = inputs.to(self.device)\n","                  labels = labels.to(self.device)\n","                  outputs = model(inputs)\n","                  _, preds = torch.max(outputs, 1)\n","                  all_true.extend(labels.cpu().numpy())\n","                  all_preds.extend(preds.cpu().numpy())\n","\n","          f1 = f1_score(all_true, all_preds, average='macro')\n","          plt.bar(name, f1, label=f'{name} (F1 = {f1:.3f})')\n","\n","      plt.xlabel('Models')\n","      plt.ylabel('Macro F1 Score')\n","      plt.title('Model Comparison - Macro F1 Scores')\n","      plt.legend()\n","      plt.xticks(rotation=45)\n","      plt.tight_layout()\n","      plt.show()\n","\n","    def plot_f1_curves(self, all_histories):\n","        \"\"\"Plot F1 score progression for multiple models\"\"\"\n","        plt.figure(figsize=(12, 6))\n","\n","        plt.subplot(1, 2, 1)\n","        for model_name, history in all_histories.items():\n","            if \"val_f1_macro\" in history:\n","                epochs = range(1, len(history[\"val_f1_macro\"]) + 1)\n","                plt.plot(epochs, history[\"val_f1_macro\"], label=model_name)\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"F1 Score\")\n","        plt.title(\"Macro F1 Score Comparison\")\n","        plt.legend()\n","        plt.grid(True)\n","\n","        plt.subplot(1, 2, 2)\n","        for model_name, history in all_histories.items():\n","            if \"val_f1_weighted\" in history:\n","                epochs = range(1, len(history[\"val_f1_weighted\"]) + 1)\n","                plt.plot(epochs, history[\"val_f1_weighted\"], label=model_name)\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"F1 Score\")\n","        plt.title(\"Weighted F1 Score Comparison\")\n","        plt.legend()\n","        plt.grid(True)\n","\n","        plt.tight_layout()\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"ab3e6fa2-1c6b-4805-8fb0-0a4460aba060","metadata":{"id":"ab3e6fa2-1c6b-4805-8fb0-0a4460aba060"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}